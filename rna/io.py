import os

import numpy as np
import torch

from pathlib import Path
from PIL import Image
import pylab as plt
import imageio
os.environ["OPENCV_IO_ENABLE_OPENEXR"] = "1"

import cv2
from torchvision.utils import flow_to_image

from .geometry import normalize as normalize_fn
from .utils import float2image
from .utils import func_linear2srgb


def read_matrix_from_file(filepath):
    with open(filepath, 'r') as fip:
        lines = [line.strip().split() for line in fip.readlines()]

    return np.array(lines, dtype=np.float32)


def read_face_uvmapping(filename):
    """Read an obj file and return the UV mapping from it.
    For additional details about obj file format, please refer to
    http://paulbourke.net/dataformats/obj/
    """
    vt = []
    ft = []
    for content in open(filename):
        line = content.strip().split(' ')
        if line[0] == 'vt': # expected 'vt u v'
            vt.append([float(a) for a in line[1:]])
        if line[0] == 'f': # expected 'v/vt/vn v/vt/vn v/vt/vn'
            ft.append([int(a.split('/')[1]) for a in line[1:] if a])

    vt = np.array(vt, dtype=np.float32)
    ft = np.array(ft, dtype=int) - 1

    return vt[ft]


def read_obj_mesh(filename, scale=1.0):
    """Read an obj file and return the vertices and faces from it.
    For additional details about obj file format, please refer to
    http://paulbourke.net/dataformats/obj/
    """
    v = []
    f = []
    for content in open(filename):
        line = content.strip().split(' ')
        if line[0] == 'v': # expected 'v x y z'
            v.append([float(a) for a in line[1:]])
        if line[0] == 'f': # expected 'f v v v'
            f.append([int(a) for a in line[1:] if a])

    return scale * np.array(v, dtype=np.float32), np.array(f, dtype=int) - 1


def write_mesh_obj(filename, vertices, faces, scale=1.0):
    """Write a mesh given by vertices and faces into an obj file.

    # Arguments
        vertices: float numpy with shape (V, 3)
        faces: integer numpy with shape (F, 3)
    """
    vertices = scale * vertices.copy()
    faces = 1 + faces.copy()
    with open(filename, 'w') as fp:
        fp.write(f'# OBJ file generated by NeuRA\n')
        fp.write(f'# vertices: {len(vertices)}\n# faces: {len(faces)}\n')
        for v in vertices:
            fp.write(f'v {v[0]:.6f} {v[1]:.6f} {v[2]:.6f}\n')
        for f in faces:
            fp.write(f'f {f[0]} {f[1]} {f[2]}\n')


def write_pts_obj(filename, pts, scale=1.0):
    """Write a point clout into an obj file.

    # Arguments
        pts: float numpy with shape (N, 3)
    """
    pts = scale * pts.copy()
    with open(filename, 'w') as fp:
        fp.write(f'# OBJ file generated by NeuRA\n')
        fp.write(f'# pts: {len(pts)}\n')
        for p in pts:
            fp.write(f'v {p[0]:.6f} {p[1]:.6f} {p[2]:.6f}\n')


def save_image(filename, arr, normalize=True):
    if isinstance(arr, torch.Tensor):
        arr = arr.detach().cpu().numpy()

    if normalize:
        arr -= arr.min()
        arr /= arr.max()
    Image.fromarray((255.5 * arr).astype(np.uint8)).save(filename)


def crop2full(buff, crop, bground=0):
    x, y, w, h, sx, sy, imw, imh = crop
    if len(buff.shape) == 2:
        shape = (imh // sy, imw // sx)
    elif len(buff.shape) == 3:
        shape = (imh // sy, imw // sx, buff.shape[2])
    else:
        raise ValueError(f'Invalid shape buff={buff.shape}!')
    y = y // sy
    h = h // sy
    x = x // sx
    w = w // sx
    out = bground * np.ones(shape, dtype=buff.dtype)
    out[y:y+h, x:x+w] = buff.copy()

    return out


def save_sampled_xyz(filename, pts):
    N, S, dim = pts.shape
    with open(filename, 'w') as fid:
        for r, ray in enumerate(pts):
            for i, p in enumerate(ray):
                fid.write(f'v {p[0]:.3f} {p[1]:.3f} {p[2]:.3f} {(1 - i / S):.2f} {(r / N):.2f} {(i / N):.2f}\n')


_a = 0.2627
_b = 0.6780
_c = 0.0593
_d = 1.8814
_e = 1.4747

_YCbCr_to_RGB_Mat = np.array([
    [1, 1, 1],
    [0, -(_c * _d / _b), _d],
    [_e, -(_a * _e / _b), 0],
], dtype=np.float32)

def ycbcr2rgb(ycbcr):
    assert ycbcr.shape[-1] == 3, f'Expected `ycbcr.shape = (..., 3)`, got {ycbcr.shape}'
    org_shape = ycbcr.shape
    rgb = ycbcr.reshape((-1, 3)) @ _YCbCr_to_RGB_Mat
    return rgb.reshape(org_shape)



def save_color_pc_obj(filename, xyz, color):
    with open(filename, 'w') as fid:
        for p, c in zip(xyz, color):
            fid.write(f'v {p[0]:.3f} {p[1]:.3f} {p[2]:.3f} {c[0]:.2f} {c[1]:.2f} {c[2]:.2f}\n')


def save_sampled_xyz_color(filename, pts, color):
    # color = np.clip((color + 1) / 2, 0, 1)
    color = ycbcr2rgb(np.stack([color[..., 2], color[..., 0], color[..., 1]], axis=-1))
    color = (color - color.min()) / (color.max() - color.min())

    with open(filename, 'w') as fid:
        for r, (ray, cray) in enumerate(zip(pts, color)):
            for i, (p, c) in enumerate(zip(ray, cray)):
                fid.write(f'v {p[0]:.3f} {p[1]:.3f} {p[2]:.3f} {c[0]:.2f} {c[1]:.2f} {c[2]:.2f}\n')


def save_prediction_data(log_dir, data, prediction, validation=True, envmap=None, postfix=''):
    Path(log_dir).mkdir(parents=True, exist_ok=True)
    # In validation mode, always have a single batch
    samples = [data['sample']] if validation else data['sample']

    if envmap is not None:
        envmap = func_linear2srgb(envmap)
        envmap = torch.reshape(envmap, (16, 32, 3)).detach().cpu().numpy()
        envmap = cv2.resize(envmap, (128, 64), interpolation=cv2.INTER_AREA)

    # run for each batch sample
    for b, spl in enumerate(samples):
        frame = int(spl[0].detach().cpu().numpy())
        camera = int(spl[1].detach().cpu().numpy())
        crop = [int(x.detach().cpu().numpy()) for x in data['crop'][b]]
        crop2image = lambda buff: crop2full(float2image(buff), crop)
        base_name = f'f_{frame:06d}_c_{camera:03d}_b_{b:02d}{postfix}'

        if envmap is not None:
            fname = os.path.join(log_dir, f'envmap_f_{frame:06d}{postfix}.png')
            Image.fromarray(float2image(envmap)).save(fname)

        if 'bground_pix' in prediction:
            w = int(crop[6] / crop[4])
            h = int(crop[7] / crop[5])
            bground_rgb = prediction['bground_pix'].view(h, w, 3).detach().cpu().numpy()
            fname = os.path.join(log_dir, f'bground_rgb_{base_name}.jpg')
            Image.fromarray(float2image(bground_rgb)).save(fname, format='JPEG', subsampling=0, quality=98)
        else:
            bground_rgb = None

        if ('rgb' in data) and (data['rgb'] is not None):
            rgb = data['rgb'][b].detach().cpu().numpy()
        else:
            rgb = None

        if ('mask' in data) and ((data['mask'] is not None)):
            mask = data['mask'][b].gt(0.5).float().detach().cpu().numpy()
        else:
            mask = None

        def getnp(key):
            if (key in prediction) and (prediction[key] is not None):
                return prediction[key][b].detach().cpu().numpy()
            return None

        texture_rgb = data['texture_rgb'].detach().cpu().numpy() if 'texture_rgb' in data else None

        mesh_depth_min = getnp('mesh_depth_min')
        mesh_depth_max = getnp('mesh_depth_max')
        mesh_hits = getnp('mesh_hits')
        mesh_color = getnp('mesh_color')
        prob_hit = getnp('prob_hit')
        pred_rgb = getnp('rgb')
        pred_relight = getnp('relight')
        pred_hdr = getnp('hdr')
        pred_albedo = getnp('albedo')
        pred_rough = getnp('rough')
        pred_depth = getnp('depth')
        pred_normals = getnp('normals')
        visibility = getnp('visibility')
        sampled_normals = getnp('sampled_normals')
        sampled_visibility = getnp('sampled_visibility')
        # uv_residual = getnp('uv_residual')
        neura_visibility = getnp('neura_visibility')
        neura_tex_rgb = getnp('neura_tex_rgb')
        neura_local_coords = getnp('neura_local_coords')
        sampled_xyz = prediction['sampled_xyz'].detach().cpu().numpy() if 'sampled_xyz' in prediction else None
        canonical_coords = prediction['canonical_coords'].detach().cpu().numpy() if 'canonical_coords' in prediction else None

        if 'uv_normals_pred' in prediction:
            uv_normals_input = normalize_fn(prediction['uv_normals_input'], axis=1)[0]
            uv_normals_input = uv_normals_input.permute(0, 2, 3, 1).squeeze(0).detach().cpu().numpy()
            fname = os.path.join(log_dir, f'uv_normals_input_f_{frame:06d}.png')
            Image.fromarray((255 * (uv_normals_input + 1) / 2).astype(np.uint8)).save(fname)

            uv_normals_pred, mag = normalize_fn(prediction['uv_normals_pred'], axis=1)
            uv_normals_pred = uv_normals_pred.permute(0, 2, 3, 1).squeeze(0).detach().cpu().numpy()
            fname = os.path.join(log_dir, f'uv_normals_pred_f_{frame:06d}.png')
            Image.fromarray((255 * (uv_normals_pred + 1) / 2).astype(np.uint8)).save(fname)

            uv_normals_pred_mask = prediction['uv_normals_pred_mask'].squeeze(1).squeeze(0).detach().cpu().numpy()
            fname = os.path.join(log_dir, f'uv_normals_pred_mask_f_{frame:06d}.png')
            Image.fromarray((255 * uv_normals_pred_mask).astype(np.uint8)).save(fname)


        if 'uv_vis_pred' in prediction:
            uv_vis_pred = prediction['uv_vis_pred'].squeeze(0).detach().cpu().numpy()
            fname = os.path.join(log_dir, f'uv_lights_pred_f_{frame:06d}.png')
            lights = np.clip(2 * uv_vis_pred.mean(axis=0), 0, 1)
            Image.fromarray((255 * lights).astype(np.uint8)).save(fname)

        if rgb is not None:
            fname = os.path.join(log_dir, f'rgb_{base_name}.jpg')
            Image.fromarray(crop2image(rgb)).save(fname, format='JPEG', subsampling=0, quality=98)

        if texture_rgb is not None:
            fname = os.path.join(log_dir, f'texture_rgb_{base_name}.png')
            Image.fromarray(float2image(texture_rgb)).save(fname)

        if mask is not None:
            # mask_ch = mask[..., np.newaxis]
            fname = os.path.join(log_dir, f'mask_{base_name}.png')
            Image.fromarray(crop2image(mask)).save(fname)

        if mesh_depth_min is not None:
            fname = os.path.join(log_dir, f'mesh_depth_min_{base_name}.png')
            de = np.zeros_like(mesh_depth_min, dtype=np.float32)
            de[mesh_hits] = np.log1p(mesh_depth_min[mesh_hits])
            # if mask is not None:
            #     de = de * mask
            de /= np.clip(de.max(), 1e-3, None)
            de_jet = plt.cm.jet(de)[..., :3] # colormap
            Image.fromarray(crop2image(de_jet)).save(fname)

        if mesh_depth_max is not None:
            fname = os.path.join(log_dir, f'mesh_depth_max_{base_name}.png')
            de = np.zeros_like(mesh_depth_max, dtype=np.float32)
            de[mesh_hits] = np.log1p(mesh_depth_max[mesh_hits])
            # if mask is not None:
            #     de = de * mask
            de /= np.clip(de.max(), 1e-3, None)
            de_jet = plt.cm.jet(de)[..., :3] # colormap
            Image.fromarray(crop2image(de_jet)).save(fname)

        if mesh_hits is not None:
            if rgb is not None:
                mesh_hits = mesh_hits[..., np.newaxis]
                mesh_hits = (1 - mesh_hits) * rgb / 2 + np.clip(2* mesh_hits * rgb, 0, 1)
            fname = os.path.join(log_dir, f'mesh_hits_{base_name}.png')
            Image.fromarray(crop2image(mesh_hits)).save(fname)

        if mesh_color is not None:
            fname = os.path.join(log_dir, f'mesh_color_{base_name}.png')
            Image.fromarray(crop2image(mesh_color)).save(fname)

        if prob_hit is not None:
            fname = os.path.join(log_dir, f'prob_hit_{base_name}.png')
            Image.fromarray(crop2image(prob_hit)).save(fname)

        if pred_rgb is not None:
            fname = os.path.join(log_dir, f'pred_rgb_{base_name}.png')
            Image.fromarray(crop2image(pred_rgb)).save(fname)

        if pred_relight is not None:
            fname = os.path.join(log_dir, f'pred_relight_{base_name}.png')
            Image.fromarray(crop2image(pred_relight)).save(fname)

            if bground_rgb is not None:
                pred_relit_img = crop2full(pred_relight, crop)
                pred_mask = crop2full(prob_hit, crop)[:, :, np.newaxis]
                composed_img = pred_mask * pred_relit_img + (1 - pred_mask) * bground_rgb
                fname = os.path.join(log_dir, f'pred_relight_composed_{base_name}.png')
                Image.fromarray(float2image(composed_img)).save(fname)

        if pred_hdr is not None:
            # fname = os.path.join(log_dir, f'pred_hdr_{base_name}.exr')
            # pred_hdr = crop2full(pred_hdr, crop)
            # imageio.imwrite(fname, pred_hdr.astype("float32"))
            fname = os.path.join(log_dir, f'pred_hdr_{base_name}.npz')
            pred_hdr = crop2full(pred_hdr, crop)
            np.savez(fname, pred_hdr)

        if pred_albedo is not None:
            fname = os.path.join(log_dir, f'pred_albedo_{base_name}.png')
            albedo = prob_hit[..., np.newaxis] * pred_albedo
            Image.fromarray(crop2image(albedo)).save(fname)

        if pred_rough is not None:
            fname = os.path.join(log_dir, f'pred_rough_{base_name}.png')
            rough = prob_hit * pred_rough[..., 0]
            Image.fromarray(crop2image(rough)).save(fname)

        if pred_depth is not None:
            fname = os.path.join(log_dir, f'pred_depth_{base_name}.png')
            # de = np.zeros_like(pred_depth, dtype=np.float32)
            # de[mesh_hits] = np.log1p(pred_depth[mesh_hits])
            # de /= np.clip(de.max(), 1e-3, None)
            de = np.log1p(pred_depth - pred_depth.min())
            de[de > np.log1p(8 - pred_depth.min())] = 0
            de /= np.clip(de.max(), 1e-3, None)
            # de = pred_depth / pred_depth.max()
            de = prob_hit * de
            de_jet = plt.cm.jet(de)[..., :3] # colormap
            # de_jet = np.concatenate([de_jet, mask_ch], axis=-1)
            Image.fromarray(crop2image(de_jet)).save(fname)

        if pred_normals is not None:
            fname = os.path.join(log_dir, f'pred_normals_{base_name}.png')
            pred_normals = (pred_normals + 1) / 2
            Image.fromarray(crop2image(pred_normals)).save(fname)

        if sampled_normals is not None:
            fname = os.path.join(log_dir, f'sampled_normals_{base_name}.png')
            sampled_normals = (sampled_normals + 1) / 2
            sampled_normals = prob_hit[..., np.newaxis] * sampled_normals
            Image.fromarray(crop2image(sampled_normals)).save(fname)

        if visibility is not None:
            for i in range(visibility.shape[-1]):
                fname = os.path.join(log_dir, f'visibility_{base_name}_e_{i:03d}.png')
                Image.fromarray(crop2image(visibility[..., i])).save(fname)

        if neura_tex_rgb is not None:
            fname = os.path.join(log_dir, f'neura_tex_rgb_{base_name}.png')
            Image.fromarray(crop2image(neura_tex_rgb)).save(fname)

        if neura_local_coords is not None:
            if neura_local_coords.shape[-1] == 3:
                fname = os.path.join(log_dir, f'neura_local_coords_{base_name}.png')
                local_coords = (neura_local_coords + 1) / 2
                Image.fromarray(crop2image(local_coords)).save(fname)
            else:
                fname = os.path.join(log_dir, f'neura_local_coords1_{base_name}.png')
                local_coords = (neura_local_coords[..., :3] + 1) / 2
                Image.fromarray(crop2image(local_coords)).save(fname)
                fname = os.path.join(log_dir, f'neura_local_coords2_{base_name}.png')
                local_coords = (neura_local_coords[..., 3:] + 1) / 2
                Image.fromarray(crop2image(local_coords)).save(fname)

        if neura_visibility is not None:
            for i in range(neura_visibility.shape[-1]):
                fname = os.path.join(log_dir, f'neura_visibility_{base_name}_e_{i:03d}.png')
                Image.fromarray(crop2image(neura_visibility[..., i])).save(fname)

        if sampled_visibility is not None:
            fname = os.path.join(log_dir, f'sampled_lights_{base_name}.png')
            sampled_visibility = np.clip(2 * (prob_hit[..., np.newaxis] * sampled_visibility).mean(-1), 0, 1)
            Image.fromarray(crop2image(sampled_visibility)).save(fname)
            # vis_path = os.path.join(log_dir, f'sampled_visibility_{base_name}')
            # Path(vis_path).mkdir(parents=True, exist_ok=True)
            # for j in range(sampled_visibility.shape[-1]):
            #     fname = os.path.join(vis_path, f'vis_{j:03d}.png')
            #     Image.fromarray(crop2image(sampled_visibility[..., j])).save(fname)

        if ('uv_residual' in prediction) and (prediction['uv_residual'] is not None):
            uv_residual = 1024 * prediction['uv_residual'][b].squeeze(0).permute(2, 0, 1)
            flow_rgb = flow_to_image(uv_residual)
            flow_rgb = flow_rgb.permute(1, 2, 0).detach().cpu().numpy()
            fname = os.path.join(log_dir, f'uv_residual_{base_name}.png')
            Image.fromarray(crop2image(flow_rgb)).save(fname)



def save_uv_geometry(datapath, uv_normals, uv_normals_mask, uv_tex, uv_tex_mask,
                     uv_vis, uv_vis_mask, frame, postfix='', debug=False):
    """
    # Arguments
        datapath: string, base path
        uv_normals: numpy array with shape (2 * tex_h, 2 * tex_w, 3)
        uv_vis: numpy array with shape (tex_h, tex_w, num_env_pix)
        frame: integer
    """
    uv_normals = np.flip(uv_normals, 0)
    uv_normals_mask = np.flip(uv_normals_mask, 0).astype(np.float32)
    # uv_tex = np.flip(uv_tex, 0)
    # uv_tex_mask = np.flip(uv_tex_mask, 0).astype(np.float32)
    uv_vis = np.flip(uv_vis, 0).astype(np.float32)
    uv_vis_mask = np.flip(uv_vis_mask, 0).astype(np.float32)

    normals_path = os.path.join(datapath, f'sampled_normals', postfix)
    Path(normals_path).mkdir(parents=True, exist_ok=True)
    uv_normals = (uv_normals + 1) / 2 # from [-1, 1] to [0, 1]
    uv_normals = uv_normals_mask[..., np.newaxis] * uv_normals
    save_image(os.path.join(normals_path, f'{frame:06d}.png'), uv_normals, normalize=False)

    # tex_path = os.path.join(datapath, f'sampled_tex', postfix)
    # Path(tex_path).mkdir(parents=True, exist_ok=True)
    # uv_tex = uv_tex_mask[..., np.newaxis] * uv_tex
    # save_image(os.path.join(tex_path, f'{frame:06d}.png'), uv_tex, normalize=False)

    lights_path = os.path.join(datapath, f'sampled_lights', postfix)
    Path(lights_path).mkdir(parents=True, exist_ok=True)
    sampled_visibility = np.clip(2 * np.mean(uv_vis, axis=-1), 0, 1)
    save_image(os.path.join(lights_path, f'{frame:06d}.png'), sampled_visibility, normalize=False)

    # for debug only
    if debug:
        for j in range(uv_vis.shape[-1]):
            v = np.clip(uv_vis[..., j], 0, 1)
            save_image(os.path.join(lights_path, f'{frame:06d}_{j:03d}.png'), v, normalize=False)

    vis_path = os.path.join(datapath, f'sampled_visibility', postfix)
    Path(vis_path).mkdir(parents=True, exist_ok=True)
    np.savez_compressed(os.path.join(vis_path, f'{frame:06d}.npz'),
                        mask=uv_vis_mask.astype(np.uint8),
                        visibility=(255.5 * uv_vis).astype(np.uint8))


def save_dbg_points(obj_filepath, rays_start, rays_dir, pts_list, colors_list, scale=1000):
    """
    # Arguments
        obj_filepath: string
        rays_start, rays_dir: tensor with shape (num_rays, 3)

    """
    assert len(rays_start) == len(rays_dir), (f'Invalid len(rays_start)!=len(rays_dir)')
    assert len(pts_list) == len(colors_list), (f'Invalid len(pts_list)!=len(colors_list)')
    s = scale

    with open(obj_filepath, 'w') as fid:
        # Write coordinate frame
        fid.write(f'v {s * 0} {s * 0} {s * 0} 0.5 0.5 0.5\n')
        fid.write(f'n 1 1 1\n')
        fid.write(f'v {s * 1} {s * 0} {s * 0} 1.0 0.0 0.0\n')
        fid.write(f'n 1 0 0\n')
        fid.write(f'v {s * 0} {s * 1} {s * 0} 0.0 1.0 0.0\n')
        fid.write(f'n 0 1 0\n')
        fid.write(f'v {s * 0} {s * 0} {s * 1} 0.0 0.0 1.0\n')
        fid.write(f'n 0 0 1\n')
        fid.write(f'l 1 2\n')
        fid.write(f'l 1 3\n')
        fid.write(f'l 1 4\n')

        rays_start = rays_start.detach().clone().cpu().numpy()
        rays_dir = rays_dir.detach().clone().cpu().numpy()
        lidx = 5 # last index from the coordinate frame
        for x, d in zip(rays_start, rays_dir):
            fid.write(f'v {s * x[0]} {s * x[1]} {s * x[2]} 1.0 0.0 1.0\n')
            fid.write(f'v {s * (x[0] + d[0])} {s * (x[1] + d[1])} {s * (x[2] + d[2])} 0.0 1.0 0.0\n')
            fid.write(f'l {lidx} {lidx+1}\n')
            lidx += 2

        for pts, c in zip(pts_list, colors_list):
            pts_np = pts.detach().clone().cpu().numpy()
            for p in pts_np:
                fid.write(f'v {s * p[0]:.3f} {s * p[1]:.3f} {s * p[2]:.3f} {c[0]:.1f} {c[1]:.1f} {c[2]:.1f}\n')



def save_points_lines_obj(obj_filepath, pts, dir,
                          pts_color=[1, 0, 1], dir_color=[0, 1, 0], scale=1):
    """
    # Arguments
        obj_filepath: string
        pts, dir: tensor with shape (N, 3)

    """
    if isinstance(pts, torch.Tensor):
        pts = pts.detach().cpu().numpy()
    if isinstance(dir, torch.Tensor):
        dir = dir.detach().cpu().numpy()

    assert pts.shape == dir.shape, (f'Invalid input shape: {pts.shape}!={dir.shape}')
    s = scale
    cp = f'{pts_color[0]:.1f} {pts_color[1]:.1f} {pts_color[2]:.1f}'
    cd = f'{dir_color[0]:.1f} {dir_color[1]:.1f} {dir_color[2]:.1f}'

    with open(obj_filepath, 'w') as fid:
        # Write coordinate frame
        fid.write(f'v {s * 0} {s * 0} {s * 0} 0.5 0.5 0.5\n')
        fid.write(f'n 1 1 1\n')
        fid.write(f'v {s * 1} {s * 0} {s * 0} 1.0 0.0 0.0\n')
        fid.write(f'n 1 0 0\n')
        fid.write(f'v {s * 0} {s * 1} {s * 0} 0.0 1.0 0.0\n')
        fid.write(f'n 0 1 0\n')
        fid.write(f'v {s * 0} {s * 0} {s * 1} 0.0 0.0 1.0\n')
        fid.write(f'n 0 0 1\n')
        fid.write(f'l 1 2\n')
        fid.write(f'l 1 3\n')
        fid.write(f'l 1 4\n')

        lidx = 5 # last index from the coordinate frame
        for p, d in zip(pts, dir):
            fid.write(f'v {s * p[0]} {s * p[1]} {s * p[2]} {cp}\n')
            fid.write(f'v {s * (p[0] + d[0])} {s * (p[1] + d[1])} {s * (p[2] + d[2])} {cd}\n')
            fid.write(f'l {lidx} {lidx+1}\n')
            lidx += 2
